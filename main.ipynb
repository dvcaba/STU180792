{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97fd5776",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install yfinance scikit-learn xgboost scikit-learn pmdarima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c578f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5afc952a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Data Loading ===\n",
      "Found data/raw/stock_data.csv. Loading data from CSV...\n",
      "Data loaded from data/raw/stock_data.csv\n",
      "\n",
      "=== Ingest: Head and Columns ===\n",
      "        Date      Close       High        Low       Open     Volume Ticker\n",
      "0 2017-01-03  26.827250  26.868824  26.506200  26.746410  115127600   AAPL\n",
      "1 2017-01-04  26.797215  26.910391  26.734853  26.757950   84472400   AAPL\n",
      "2 2017-01-05  26.933491  26.991233  26.748714  26.774120   88774400   AAPL\n",
      "3 2017-01-06  27.233751  27.291494  26.901153  26.972753  127007600   AAPL\n",
      "4 2017-01-09  27.483202  27.584830  27.240684  27.242992  134247600   AAPL\n",
      "Columnas: ['Date', 'Close', 'High', 'Low', 'Open', 'Volume', 'Ticker']\n",
      "Filtered data to ^GSPC only\n",
      "\n",
      "=== Adding Technical Indicators ===\n",
      "Added RSI, MACD, and Bollinger Bands\n",
      "\n",
      "=== Feature Engineering: Head and Columns ===\n",
      "           Date        Close         High          Low         Open  \\\n",
      "5252 2017-01-31  2278.870117  2279.090088  2267.209961  2274.020020   \n",
      "5253 2017-02-01  2279.550049  2289.139893  2272.439941  2285.590088   \n",
      "5254 2017-02-02  2280.850098  2283.969971  2271.649902  2276.689941   \n",
      "5255 2017-02-03  2297.419922  2298.310059  2287.879883  2288.540039   \n",
      "5256 2017-02-06  2292.560059  2296.179932  2288.570068  2294.280029   \n",
      "\n",
      "          Volume Ticker        RSI      MACD  MACD_Signal  MACD_Hist  \\\n",
      "5252  4089730000  ^GSPC  54.943062  6.438776     5.530402   0.908374   \n",
      "5253  3919190000  ^GSPC  52.223722  5.911025     5.606527   0.304498   \n",
      "5254  3809760000  ^GSPC  55.686728  5.533890     5.591999  -0.058109   \n",
      "5255  3605970000  ^GSPC  60.962463  6.497159     5.773031   0.724128   \n",
      "5256  3112390000  ^GSPC  62.092032  6.790134     5.976452   0.813683   \n",
      "\n",
      "        BB_Middle     BB_Upper     BB_Lower  \n",
      "5252  2275.115979  2296.759682  2253.472276  \n",
      "5253  2276.201978  2296.319567  2256.084388  \n",
      "5254  2276.706982  2296.755282  2256.658682  \n",
      "5255  2278.127979  2299.836244  2256.419713  \n",
      "5256  2278.906982  2301.540269  2256.273696  \n",
      "Columnas: ['Date', 'Close', 'High', 'Low', 'Open', 'Volume', 'Ticker', 'RSI', 'MACD', 'MACD_Signal', 'MACD_Hist', 'BB_Middle', 'BB_Upper', 'BB_Lower']\n",
      "\n",
      "=== Running Exploratory Data Analysis ===\n",
      "Shape: (2114, 15)\n",
      "\n",
      "Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 2114 entries, 5252 to 7365\n",
      "Data columns (total 15 columns):\n",
      " #   Column        Non-Null Count  Dtype         \n",
      "---  ------        --------------  -----         \n",
      " 0   Date          2114 non-null   datetime64[ns]\n",
      " 1   Close         2114 non-null   float64       \n",
      " 2   High          2114 non-null   float64       \n",
      " 3   Low           2114 non-null   float64       \n",
      " 4   Open          2114 non-null   float64       \n",
      " 5   Volume        2114 non-null   int64         \n",
      " 6   Ticker        2114 non-null   object        \n",
      " 7   RSI           2114 non-null   float64       \n",
      " 8   MACD          2114 non-null   float64       \n",
      " 9   MACD_Signal   2114 non-null   float64       \n",
      " 10  MACD_Hist     2114 non-null   float64       \n",
      " 11  BB_Middle     2114 non-null   float64       \n",
      " 12  BB_Upper      2114 non-null   float64       \n",
      " 13  BB_Lower      2114 non-null   float64       \n",
      " 14  Daily Return  2113 non-null   float64       \n",
      "dtypes: datetime64[ns](1), float64(12), int64(1), object(1)\n",
      "memory usage: 264.2+ KB\n",
      "None\n",
      "\n",
      "Missing values:\n",
      "Date            0\n",
      "Close           0\n",
      "High            0\n",
      "Low             0\n",
      "Open            0\n",
      "Volume          0\n",
      "Ticker          0\n",
      "RSI             0\n",
      "MACD            0\n",
      "MACD_Signal     0\n",
      "MACD_Hist       0\n",
      "BB_Middle       0\n",
      "BB_Upper        0\n",
      "BB_Lower        0\n",
      "Daily Return    1\n",
      "dtype: int64\n",
      "\n",
      "Statistical Summary:\n",
      "                                Date        Close         High          Low  \\\n",
      "count                           2114  2114.000000  2114.000000  2114.000000   \n",
      "mean   2021-04-12 06:21:27.417218560  3810.982819  3831.401130  3787.682846   \n",
      "min              2017-01-31 00:00:00  2237.399902  2279.090088  2191.860107   \n",
      "25%              2019-03-08 18:00:00  2831.174988  2843.434937  2812.784973   \n",
      "50%              2021-04-13 12:00:00  3825.005005  3856.525024  3799.229980   \n",
      "75%              2023-05-17 18:00:00  4481.037476  4503.092529  4457.854980   \n",
      "max              2025-06-27 00:00:00  6173.069824  6187.680176  6132.350098   \n",
      "std                              NaN  1066.732239  1071.913905  1060.543949   \n",
      "\n",
      "              Open        Volume          RSI         MACD  MACD_Signal  \\\n",
      "count  2114.000000  2.114000e+03  2114.000000  2114.000000  2114.000000   \n",
      "mean   3810.256907  4.126642e+09    57.142888    12.088974    11.961390   \n",
      "min    2274.020020  0.000000e+00     4.009864  -237.020227  -198.640715   \n",
      "25%    2829.702576  3.493485e+09    45.116845    -4.502793    -3.460779   \n",
      "50%    3829.310059  3.907265e+09    58.707017    18.907776    18.556531   \n",
      "75%    4482.337524  4.524928e+09    68.606669    39.300433    36.840919   \n",
      "max    6150.700195  9.976520e+09    96.234267   121.081850    95.568906   \n",
      "std    1066.259492  1.029561e+09    16.382528    43.097906    40.072684   \n",
      "\n",
      "         MACD_Hist    BB_Middle     BB_Upper     BB_Lower  Daily Return  \n",
      "count  2114.000000  2114.000000  2114.000000  2114.000000   2113.000000  \n",
      "mean      0.127584  3794.049393  3921.982829  3666.115957      0.000544  \n",
      "min     -64.504424  2275.115979  2296.319567  2099.912466     -0.119841  \n",
      "25%      -5.701160  2825.936768  2923.795344  2744.168087     -0.003864  \n",
      "50%       0.677120  3839.765265  3978.532087  3675.406691      0.000819  \n",
      "75%       5.894090  4458.357233  4611.058175  4327.762902      0.006195  \n",
      "max      60.895804  6073.114478  6282.042881  5993.082579      0.095154  \n",
      "std      13.991380  1058.313453  1096.050634  1026.473135      0.012008  \n",
      "EDA plots saved to results/eda/\n",
      "Columns analyzed EDA: ['Date', 'Close', 'High', 'Low', 'Open', 'Volume', 'Ticker', 'RSI', 'MACD', 'MACD_Signal', 'MACD_Hist', 'BB_Middle', 'BB_Upper', 'BB_Lower']\n",
      "\n",
      "=== Preprocessing Data ===\n",
      "Removed 117 outliers from Volume\n",
      "Removed 120 outliers from Daily Return\n",
      "\n",
      "=== Processed: Head and Columns ===\n",
      "        Date Ticker      Open      High       Low     Close    Volume  \\\n",
      "0 2017-02-14  ^GSPC -1.398777 -1.398713 -1.392844 -1.390189 -0.592680   \n",
      "1 2017-02-15  ^GSPC -1.389955 -1.385986 -1.380990 -1.379308 -0.213871   \n",
      "2 2017-02-16  ^GSPC -1.376843 -1.385977 -1.377182 -1.381201 -0.375441   \n",
      "3 2017-02-17  ^GSPC -1.383026 -1.386116 -1.376516 -1.377527 -0.609150   \n",
      "4 2017-02-21  ^GSPC -1.371928 -1.371692 -1.362140 -1.364269 -0.505291   \n",
      "\n",
      "   Daily Return  Volatility_5d      MA_5  ...  Return_Lag_4  Return_Lag_5  \\\n",
      "0      0.369472      -1.165957 -1.405712  ...     -0.017252     -0.060857   \n",
      "1      0.503129      -1.375028 -1.395511  ...      0.493748     -0.012488   \n",
      "2     -0.291562      -1.068970 -1.388156  ...      0.272904      0.512084   \n",
      "3      0.053467      -1.047988 -1.381604  ...      0.442570      0.285375   \n",
      "4      0.646391      -1.010799 -1.374664  ...      0.317476      0.459546   \n",
      "\n",
      "        RSI      MACD  MACD_Signal  MACD_Hist  BB_Middle  BB_Upper  BB_Lower  \\\n",
      "0  0.870727 -0.090490    -0.200497   0.288905  -1.419395 -1.438527 -1.394029   \n",
      "1  1.161158 -0.020893    -0.158936   0.375934  -1.415756 -1.429094 -1.396633   \n",
      "2  1.159153  0.023819    -0.116274   0.388026  -1.411826 -1.422617 -1.395457   \n",
      "3  1.992807  0.061931    -0.074121   0.382443  -1.408070 -1.416071 -1.394712   \n",
      "4  2.200545  0.117524    -0.028694   0.418390  -1.403357 -1.408250 -1.393357   \n",
      "\n",
      "   Target  \n",
      "0       0  \n",
      "1       1  \n",
      "2       1  \n",
      "3       1  \n",
      "4       0  \n",
      "\n",
      "[5 rows x 41 columns]\n",
      "Columns: ['Date', 'Ticker', 'Open', 'High', 'Low', 'Close', 'Volume', 'Daily Return', 'Volatility_5d', 'MA_5', 'MA_10', 'Delta_Close', 'Range', 'Weekday', 'Volume_Change', 'Price_to_Volume', 'Momentum_3d', 'Rolling_Return_5d', 'Lag_1', 'Lag_2', 'Lag_3', 'Lag_4', 'Lag_5', 'Lag_6', 'Lag_7', 'Lag_8', 'Lag_9', 'Lag_10', 'Return_Lag_1', 'Return_Lag_2', 'Return_Lag_3', 'Return_Lag_4', 'Return_Lag_5', 'RSI', 'MACD', 'MACD_Signal', 'MACD_Hist', 'BB_Middle', 'BB_Upper', 'BB_Lower', 'Target']\n",
      "\n",
      "=== Training Baseline Model ===\n",
      "\n",
      "================================================================================\n",
      "BASELINE MODEL RESULTS\n",
      "================================================================================\n",
      " Accuracy  Precision   Recall  F1 Score  ROC AUC\n",
      " 0.419786   0.407407 0.051887   0.09205 0.477725\n",
      "\n",
      "Results saved to: results/global_comparison/baseline_results.csv\n",
      "\n",
      "================================================================================\n",
      "STARTING GRID SEARCH PHASE\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "GRID SEARCH - BEST MODEL OF EACH TYPE\n",
      "================================================================================\n",
      " Accuracy  Precision   Recall  F1 Score  ROC AUC                  Model\n",
      " 0.425134   0.463415 0.089623  0.150198 0.464594     LogisticRegression\n",
      " 0.465241   0.575000 0.216981  0.315068 0.505532 RandomForestClassifier\n",
      " 0.433155   0.500000 0.193396  0.278912 0.420568          XGBClassifier\n",
      " 0.465241   0.676471 0.108491  0.186992 0.467418                    SVC\n",
      "\n",
      "Results saved to: results/grid_search/metrics/grid_search_best_models_comparison.csv\n",
      "\n",
      "--- Best hiperparameters found with GRID SEARCH ---\n",
      "Grid Search (LogisticRegression): {'C': 10.0, 'max_iter': 200.0, 'solver': 'lbfgs'}\n",
      "Grid Search (RandomForestClassifier): {'max_depth': 10.0, 'n_estimators': 50.0, 'random_state': 42.0}\n",
      "Grid Search (XGBClassifier): {'max_depth': 6.0, 'n_estimators': 100.0, 'random_state': 42.0, 'learning_rate': 0.01}\n",
      "Grid Search (SVC): {'C': 10.0, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "\n",
      "================================================================================\n",
      "STARTING RANDOM SEARCH PHASE\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "RANDOM SEARCH - BEST MODEL OF EACH TYPE\n",
      "================================================================================\n",
      " Accuracy  Precision   Recall  F1 Score  ROC AUC                  Model\n",
      " 0.419786   0.452830 0.113208  0.181132 0.456208     LogisticRegression\n",
      " 0.473262   0.533040 0.570755  0.551253 0.447152 RandomForestClassifier\n",
      " 0.462567   0.547009 0.301887  0.389058 0.474755          XGBClassifier\n",
      " 0.532086   0.568266 0.726415  0.637681 0.514879                    SVC\n",
      "\n",
      "Results saved to: results/random_search/metrics/random_search_best_models_comparison.csv\n",
      "\n",
      "--- Best hiperparameters found with RANDOM SEARCH ---\n",
      "Random Search (LogisticRegression): {'solver': 'newton-cg', 'penalty': 'l2', 'max_iter': 200.0, 'C': 100.0}\n",
      "Random Search (RandomForestClassifier): {'random_state': 42.0, 'n_estimators': 100.0, 'min_samples_split': 10.0, 'min_samples_leaf': 1.0, 'max_depth': 15.0, 'bootstrap': True}\n",
      "Random Search (XGBClassifier): {'random_state': 42.0, 'n_estimators': 200.0, 'max_depth': 8.0, 'subsample': 0.6, 'reg_lambda': 0.0, 'reg_alpha': 0.001, 'learning_rate': 0.3, 'gamma': 0.3, 'colsample_bytree': 0.8}\n",
      "Random Search (SVC): {'C': 10.0, 'gamma': 0.1, 'kernel': 'poly', 'degree': 2.0, 'coef0': 0.0}\n",
      "\n",
      "================================================================================\n",
      "GLOBAL COMPARISON - BEST OF EACH MODEL TYPE\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "GLOBAL - BEST VERSION OF EACH MODEL TYPE\n",
      "================================================================================\n",
      " Accuracy  Precision   Recall  F1 Score  ROC AUC                  Model Search Method\n",
      " 0.419786   0.452830 0.113208  0.181132 0.456208     LogisticRegression Random Search\n",
      " 0.473262   0.533040 0.570755  0.551253 0.447152 RandomForestClassifier Random Search\n",
      " 0.462567   0.547009 0.301887  0.389058 0.474755          XGBClassifier Random Search\n",
      " 0.532086   0.568266 0.726415  0.637681 0.514879                    SVC Random Search\n",
      "\n",
      "Results saved to: results/global_comparison/global_best_of_each_model_type.csv\n",
      "\n",
      "================================================================================\n",
      "*** GLOBAL BEST MODEL ***\n",
      "Model: SVC\n",
      "F1 Score: 0.6377\n",
      "Recall: 0.7264\n",
      "Accuracy: 0.5321\n",
      "Precision: 0.5683\n",
      "ROC AUC: 0.5149\n",
      "Hyperparameters: {'C': 10.0, 'gamma': 0.1, 'kernel': 'poly', 'degree': 2.0, 'coef0': 0.0}\n",
      "================================================================================\n",
      "Predictions saved to results\\best_model_predictions.csv\n",
      "[1 1 0 0 0 0 1 0 1 1 1 0 1 1 0 1 0 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 1 1 1 0\n",
      " 0 0 0 0 1 0 0 1 0 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 1 0 0 1 0 0 1 1 1 1\n",
      " 1 1 1 1 0 0 1 0 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 1 0 0 1 0 0 0 0 1 1 1 1 0 1\n",
      " 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0 0 1 0 1 1 1 1 1 0 1 1 1 0 1 0\n",
      " 1 0 0 0 0 0 1 1 1 0 1 1 0 0 1 1 0 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 0 1 1 1 1 1 0 1 1 1 1 1 0 1 0 1 1 1 0 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 0 1 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 0 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1\n",
      " 0 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 0 1 0 0 0 0 1 0 0 0 1 1 0 1 0 0 0 0\n",
      " 0 1 1 1]\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Key files:\n",
      "- Baseline: results/global_comparison/baseline_results.csv\n",
      "- Best Grid Search: results/grid_search/metrics/grid_search_overall_best.csv\n",
      "- Best Random Search: results/random_search/metrics/random_search_overall_best.csv\n",
      "- Global Best: results/global_best/global_best_model_info.csv\n"
     ]
    }
   ],
   "source": [
    "# === Standard library imports ===\n",
    "import os  # Provides functions to interact with the operating system\n",
    "import shutil  # Used to copy and remove files or directories\n",
    "import pandas as pd  # For data manipulation and analysis\n",
    "import io  # For managing input/output streams\n",
    "import sys  # System-specific parameters and functions\n",
    "from contextlib import redirect_stdout  # Temporarily redirects standard output\n",
    "\n",
    "# === Project-specific module imports ===\n",
    "from ingest.stock_data_fetcher import StockDataFetcher  # Handles fetching stock data\n",
    "from preprocessing.data_preprocessor import DataPreprocessor  # Preprocesses the dataset\n",
    "from feature_engineering.technical_indicators import TechnicalIndicators  # Adds technical indicators to the data\n",
    "from eda.stock_eda import StockEDA  # Performs exploratory data analysis\n",
    "\n",
    "# Import machine learning model wrappers\n",
    "from models.random_forest import RandomForestModel\n",
    "from models.logistic_regression import LogisticModel\n",
    "from models.xgboost_model import XGBoostClassifierModel\n",
    "from models.svm_model import SVMClassifierModel\n",
    "\n",
    "# Import evaluation tools\n",
    "from evaluation.metrics import save_and_display_results  # Saves and displays performance metrics\n",
    "from evaluation.evaluation_utils import rename_model_plots  # Renames plot files for easier comparison\n",
    "\n",
    "# Import scikit-learn and joblib for model training and saving\n",
    "from sklearn.model_selection import train_test_split  # Splits dataset into train/test sets\n",
    "import joblib  # Saves and loads trained models to/from disk\n",
    "\n",
    "# Hyperparameter tuning utilities\n",
    "from models.grid_search_wrapper import run_grid_search_with_all_saves  # Grid search with logging and saving\n",
    "from models.random_search_wrapper import run_random_search_with_all_saves  # Randomized search with logging and saving\n",
    "\n",
    "# === Miscellaneous setup ===\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')  # Ignore all warnings to keep output clean\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import yaml  # For loading configuration files\n",
    "\n",
    "# === Set global seed for reproducibility ===\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# === Load hyperparameter configuration file ===\n",
    "with open(\"config.yaml\", \"r\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "# === Extract pipeline-level configuration ===\n",
    "pipeline_cfg = config.get(\"pipeline\", {})\n",
    "TICKERS = pipeline_cfg.get(\"tickers\", [\"AAPL\", \"BTC-USD\", \"^GSPC\"])  # Default tickers\n",
    "START_DATE = pipeline_cfg.get(\"start_date\", \"2017-01-01\")  # Default start date\n",
    "FILTER_TICKER = pipeline_cfg.get(\"filter_ticker\", \"^GSPC\")  # Main ticker to focus on\n",
    "FORECAST_HORIZON = pipeline_cfg.get(\"forecast_horizon\", 5)  # Number of days to forecast\n",
    "\n",
    "# === Create necessary folders if they don't exist ===\n",
    "for path in [\n",
    "    \"data/raw\", \"data/preprocessed\",\n",
    "    \"results/eda\",\n",
    "    \"results/grid_search/best_models\", \"results/grid_search/metrics\", \n",
    "    \"results/grid_search/plots\", \"results/grid_search/all_executions\",\n",
    "    \"results/random_search/best_models\", \"results/random_search/metrics\",\n",
    "    \"results/random_search/plots\", \"results/random_search/all_executions\",\n",
    "    \"results/global_best\", \"results/global_comparison\"\n",
    "    ]:\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "\n",
    "# === Step 1: Fetch or load stock data ===\n",
    "print(\"\\n=== Data Loading ===\")\n",
    "csv_path = \"data/raw/stock_data.csv\"\n",
    "if os.path.exists(csv_path):\n",
    "    # If data already exists locally, load it\n",
    "    print(f\"Found {csv_path}. Loading data from CSV...\")\n",
    "    df = StockDataFetcher.load_from_csv(csv_path)\n",
    "else:\n",
    "    # If not, fetch it from Yahoo Finance and save it\n",
    "    print(f\"File {csv_path} not found. Downloading data from Yahoo Finance...\")\n",
    "    fetcher = StockDataFetcher(ticker=TICKERS, start_date=START_DATE)\n",
    "    df = fetcher.fetch()\n",
    "    fetcher.save_to_csv(csv_path)\n",
    "    fetcher.quick_summary()\n",
    "\n",
    "# Display head and columns of the ingested data\n",
    "print(\"\\n=== Ingest: Head and Columns ===\")\n",
    "print(df.head())\n",
    "print(\"Columnas:\", df.columns.tolist())\n",
    "\n",
    "# === Step 2: Filter data for a specific ticker ===\n",
    "df = df[df[\"Ticker\"] == FILTER_TICKER].copy()\n",
    "print(f\"Filtered data to {FILTER_TICKER} only\")\n",
    "\n",
    "# === Step 3: Add technical indicators ===\n",
    "print(\"\\n=== Adding Technical Indicators ===\")\n",
    "df = (\n",
    "    TechnicalIndicators(df)\n",
    "    .add_rsi()  # Add Relative Strength Index\n",
    "    .add_macd()  # Add Moving Average Convergence Divergence\n",
    "    .add_bollinger_bands()  # Add Bollinger Bands\n",
    "    .get_data()\n",
    "    .dropna()  # Drop rows with missing values\n",
    ")\n",
    "print(\"Added RSI, MACD, and Bollinger Bands\")\n",
    "print(\"\\n=== Feature Engineering: Head and Columns ===\")\n",
    "print(df.head())\n",
    "print(\"Columnas:\", df.columns.tolist())\n",
    "\n",
    "# === Step 4: Perform exploratory data analysis (EDA) ===\n",
    "print(\"\\n=== Running Exploratory Data Analysis ===\")\n",
    "eda = StockEDA(df)\n",
    "eda.run_all(save_dir=\"results/eda\")  # Save all EDA plots\n",
    "print(\"EDA plots saved to results/eda/\")\n",
    "print(\"Columns analyzed EDA:\", df.columns.tolist())\n",
    "\n",
    "# === Step 5: Preprocess the data ===\n",
    "print(\"\\n=== Preprocessing Data ===\")\n",
    "preprocessor = DataPreprocessor(\n",
    "    data=df,\n",
    "    scale=\"standard\",  # StandardScaler for feature scaling\n",
    "    model_type=\"classification\",  # Classification task\n",
    "    target_type=\"direction\",  # Predict direction of price movement\n",
    "    forecast_horizon=FORECAST_HORIZON  # Number of days to predict ahead\n",
    ")\n",
    "df_processed = preprocessor.preprocess()\n",
    "df_processed.to_csv(\"data/preprocessed/stock_data_preprocessed.csv\", index=False)\n",
    "print(\"\\n=== Processed: Head and Columns ===\")\n",
    "print(df_processed.head())\n",
    "print(\"Columns:\", df_processed.columns.tolist())\n",
    "\n",
    "# === Step 6: Train baseline model (Logistic Regression) ===\n",
    "print(\"\\n=== Training Baseline Model ===\")\n",
    "f = io.StringIO()\n",
    "with redirect_stdout(f):  # Suppress training output\n",
    "    baseline_model = LogisticModel(df_processed)\n",
    "    baseline_model.run_all()\n",
    "\n",
    "# Load and save baseline metrics\n",
    "baseline_metrics = pd.read_csv(\"results/metrics/LogisticRegression_metrics.csv\")\n",
    "baseline_metrics.to_csv(\"results/global_comparison/baseline_LogisticRegression_metrics.csv\", index=False)\n",
    "\n",
    "# Display baseline results\n",
    "save_and_display_results(\n",
    "    baseline_metrics,\n",
    "    \"results/global_comparison/baseline_results.csv\",\n",
    "    \"BASELINE MODEL RESULTS\"\n",
    ")\n",
    "\n",
    "# === Step 7: Grid search for hyperparameter tuning ===\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STARTING GRID SEARCH PHASE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "grid_search_results = []\n",
    "\n",
    "# Logistic Regression\n",
    "log_params = config[\"grid_search\"][\"logistic_regression\"]\n",
    "_, _, log_metrics = run_grid_search_with_all_saves(LogisticModel, df_processed, log_params, \"f1\", \"LogisticRegression\", \"grid\")\n",
    "grid_search_results.append(log_metrics)\n",
    "\n",
    "# Random Forest\n",
    "rf_params = config[\"grid_search\"][\"random_forest\"]\n",
    "_, _, rf_metrics = run_grid_search_with_all_saves(RandomForestModel, df_processed, rf_params, \"f1\", \"RandomForest\", \"grid\")\n",
    "grid_search_results.append(rf_metrics)\n",
    "\n",
    "# XGBoost\n",
    "xgb_params = config[\"grid_search\"][\"xgboost\"]\n",
    "_, _, xgb_metrics = run_grid_search_with_all_saves(XGBoostClassifierModel, df_processed, xgb_params, \"f1\", \"XGBoost\", \"grid\")\n",
    "grid_search_results.append(xgb_metrics)\n",
    "\n",
    "# Support Vector Machine\n",
    "svm_params = config[\"grid_search\"][\"svm\"]\n",
    "_, _, svm_metrics = run_grid_search_with_all_saves(SVMClassifierModel, df_processed, svm_params, \"f1\", \"SVM\", \"grid\")\n",
    "grid_search_results.append(svm_metrics)\n",
    "\n",
    "# Save and display grid search comparison\n",
    "grid_results_df = pd.DataFrame(grid_search_results)\n",
    "save_and_display_results(\n",
    "    grid_results_df,\n",
    "    \"results/grid_search/metrics/grid_search_best_models_comparison.csv\",\n",
    "    \"GRID SEARCH - BEST MODEL OF EACH TYPE\"\n",
    ")\n",
    "\n",
    "# Print best hyperparameters per model from grid search\n",
    "print(\"\\n--- Best hiperparameters found with GRID SEARCH ---\")\n",
    "for _, row in grid_results_df.iterrows():\n",
    "    model_name = row[\"Model\"]\n",
    "    param_keys = [k for k in row.index if k not in [\"Model\", \"Accuracy\", \"Precision\", \"Recall\", \"F1 Score\", \"ROC AUC\"]]\n",
    "    param_values = {k: row[k] for k in param_keys if pd.notnull(row[k])}\n",
    "    print(f\"Grid Search ({model_name}): {param_values}\")\n",
    "\n",
    "# === Step 8: Random search for hyperparameter tuning ===\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STARTING RANDOM SEARCH PHASE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "random_search_results = []\n",
    "\n",
    "# Logistic Regression\n",
    "log_distributions = config[\"random_search\"][\"logistic_regression\"]\n",
    "_, _, log_rs_metrics = run_random_search_with_all_saves(LogisticModel, df_processed, log_distributions, 10, \"f1\", \"LogisticRegression\")\n",
    "random_search_results.append(log_rs_metrics)\n",
    "\n",
    "# Random Forest\n",
    "rf_distributions = config[\"random_search\"][\"random_forest\"]\n",
    "_, _, rf_rs_metrics = run_random_search_with_all_saves(RandomForestModel, df_processed, rf_distributions, 15, \"f1\", \"RandomForest\")\n",
    "random_search_results.append(rf_rs_metrics)\n",
    "\n",
    "# XGBoost\n",
    "xgb_distributions = config[\"random_search\"][\"xgboost\"]\n",
    "_, _, xgb_rs_metrics = run_random_search_with_all_saves(XGBoostClassifierModel, df_processed, xgb_distributions, 20, \"f1\", \"XGBoost\")\n",
    "random_search_results.append(xgb_rs_metrics)\n",
    "\n",
    "# Support Vector Machine\n",
    "svm_distributions = config[\"random_search\"][\"svm\"]\n",
    "_, _, svm_rs_metrics = run_random_search_with_all_saves(SVMClassifierModel, df_processed, svm_distributions, 15, \"f1\", \"SVM\")\n",
    "random_search_results.append(svm_rs_metrics)\n",
    "\n",
    "# Save and display random search comparison\n",
    "random_results_df = pd.DataFrame(random_search_results)\n",
    "save_and_display_results(\n",
    "    random_results_df,\n",
    "    \"results/random_search/metrics/random_search_best_models_comparison.csv\",\n",
    "    \"RANDOM SEARCH - BEST MODEL OF EACH TYPE\"\n",
    ")\n",
    "\n",
    "# Print best hyperparameters per model from random search\n",
    "print(\"\\n--- Best hiperparameters found with RANDOM SEARCH ---\")\n",
    "for _, row in random_results_df.iterrows():\n",
    "    model_name = row[\"Model\"]\n",
    "    param_keys = [k for k in row.index if k not in [\"Model\", \"Accuracy\", \"Precision\", \"Recall\", \"F1 Score\", \"ROC AUC\"]]\n",
    "    param_values = {k: row[k] for k in param_keys if pd.notnull(row[k])}\n",
    "    print(f\"Random Search ({model_name}): {param_values}\")\n",
    "\n",
    "# === Step 9: Compare best grid vs random per model ===\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"GLOBAL COMPARISON - BEST OF EACH MODEL TYPE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "model_types = [\"LogisticRegression\", \"RandomForestClassifier\", \"XGBClassifier\", \"SVC\"]\n",
    "global_best_models = []\n",
    "\n",
    "# For each model type, compare the best from grid vs random search\n",
    "for model_type in model_types:\n",
    "    grid_model = grid_results_df[grid_results_df[\"Model\"] == model_type]\n",
    "    random_model = random_results_df[random_results_df[\"Model\"] == model_type]\n",
    "    \n",
    "    if not grid_model.empty and not random_model.empty:\n",
    "        if grid_model.iloc[0][\"F1 Score\"] >= random_model.iloc[0][\"F1 Score\"]:\n",
    "            best = grid_model.iloc[0].copy()\n",
    "            best[\"Search Method\"] = \"Grid Search\"\n",
    "        else:\n",
    "            best = random_model.iloc[0].copy()\n",
    "            best[\"Search Method\"] = \"Random Search\"\n",
    "        global_best_models.append(best.to_dict())\n",
    "\n",
    "# Save best version of each model type\n",
    "global_comparison_df = pd.DataFrame(global_best_models)\n",
    "save_and_display_results(\n",
    "    global_comparison_df[[\"Model\", \"Search Method\", \"Accuracy\", \"Precision\", \"Recall\", \"F1 Score\", \"ROC AUC\"]],\n",
    "    \"results/global_comparison/global_best_of_each_model_type.csv\",\n",
    "    \"GLOBAL - BEST VERSION OF EACH MODEL TYPE\"\n",
    ")\n",
    "\n",
    "# === Step 10: Identify overall best model ===\n",
    "all_results = grid_search_results + random_search_results\n",
    "all_results_df = pd.DataFrame(all_results)\n",
    "\n",
    "# Sort by F1 Score and Recall\n",
    "best_overall = all_results_df.sort_values(by=[\"F1 Score\", \"Recall\"], ascending=[False, False]).iloc[0]\n",
    "best_model_name = best_overall[\"Model\"]\n",
    "\n",
    "# Display best model info\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"*** GLOBAL BEST MODEL ***\")\n",
    "print(f\"Model: {best_model_name}\")\n",
    "print(f\"F1 Score: {best_overall['F1 Score']:.4f}\")\n",
    "print(f\"Recall: {best_overall['Recall']:.4f}\")\n",
    "print(f\"Accuracy: {best_overall['Accuracy']:.4f}\")\n",
    "print(f\"Precision: {best_overall['Precision']:.4f}\")\n",
    "print(f\"ROC AUC: {best_overall['ROC AUC']:.4f}\")\n",
    "\n",
    "# Extract hyperparameters from best model\n",
    "standard_metrics = {\"Model\", \"Accuracy\", \"Precision\", \"Recall\", \"F1 Score\", \"ROC AUC\", \"Search Method\"}\n",
    "hyperparams = {\n",
    "    k: (float(v) if isinstance(v, (np.floating, float)) else v)\n",
    "    for k, v in best_overall.items()\n",
    "    if k not in standard_metrics and pd.notnull(v)\n",
    "}\n",
    "print(\"Hyperparameters:\", hyperparams)\n",
    "print(f\"{'='*80}\")\n",
    "\n",
    "# Save best model info to disk\n",
    "pd.DataFrame([best_overall]).to_csv(\n",
    "    \"results/global_best/global_best_model_info.csv\", \n",
    "    index=False\n",
    ")\n",
    "\n",
    "# Copy model and metrics files to global_best folder\n",
    "src_model = os.path.join(\"results/best_models\", f\"{best_model_name}.pkl\")\n",
    "dst_model = os.path.join(\"results/global_best\", f\"global_best_{best_model_name}.pkl\")\n",
    "src_metrics = os.path.join(\"results/best_models\", f\"{best_model_name}_metrics.csv\")\n",
    "dst_metrics = os.path.join(\"results/global_best\", f\"global_best_{best_model_name}_metrics.csv\")\n",
    "\n",
    "if os.path.exists(src_model):\n",
    "    shutil.copy2(src_model, dst_model)\n",
    "    shutil.copy2(src_metrics, dst_metrics)\n",
    "\n",
    "# Copy plots (confusion matrix, ROC, feature importance)\n",
    "source_dirs = [\"results/confusion_matrices\", \"results/roc_curves\", \"results/feature_importance\"]\n",
    "rename_model_plots(best_model_name, source_dirs, \"results/global_best\", \"global_best\")\n",
    "\n",
    "# === Step 11: Generate predictions using the best model ===\n",
    "best_model_path = os.path.join(\"results/best_models\", f\"{best_model_name}.pkl\")\n",
    "if os.path.exists(best_model_path):\n",
    "    loaded_model = joblib.load(best_model_path)\n",
    "    features = df_processed.drop(columns=[\"Date\", \"Ticker\", \"Target\"])\n",
    "    target = df_processed[\"Target\"]\n",
    "    _, X_test, _, _ = train_test_split(features, target, test_size=0.2, shuffle=False)\n",
    "    preds = loaded_model.predict(X_test)\n",
    "    os.makedirs(\"results\", exist_ok=True)\n",
    "    pred_path = os.path.join(\"results\", \"best_model_predictions.csv\")\n",
    "    pd.DataFrame(preds, columns=[\"Prediction\"]).to_csv(pred_path, index=False)\n",
    "    print(f\"Predictions saved to {pred_path}\")\n",
    "    print(preds)\n",
    "\n",
    "else:\n",
    "    print(f\"Best model file {best_model_path} not found. Skipping prediction step.\")\n",
    "\n",
    "# === Final summary with key result files ===\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"\\nKey files:\")\n",
    "print(f\"- Baseline: results/global_comparison/baseline_results.csv\")\n",
    "print(f\"- Best Grid Search: results/grid_search/metrics/grid_search_overall_best.csv\")\n",
    "print(f\"- Best Random Search: results/random_search/metrics/random_search_overall_best.csv\")\n",
    "print(f\"- Global Best: results/global_best/global_best_model_info.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e40580",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93180888",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5fbd449",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c924b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd1fb46",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
